{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# uncomment below lines to install the required packages\n",
    "# !pip install pandas pandas-ta scikit-learn xgboost\n",
    "# !pip install matplotlib seaborn mplfinance\n",
    "# !pip install tensorflow   # for deep learning models"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mplfinance as mpf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from xgboost import XGBRegressor"
   ],
   "id": "731b1669a0758690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/AARTIIND.NS_20220608_20240607_1d.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# vstop_plt = mpf.make_addplot(df.iloc[10:20, -1], type='scatter', marker='+', markersize=50)\n",
    "# mpf.plot(df.iloc[10:20, :], type='candle', style='yahoo', volume=True, addplot=vstop_plt)"
   ],
   "id": "64fcae2df5f4e072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Add a Target column with the next day's gain/loss as a percent value**",
   "id": "940c69935a24d816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['Target'] = (df['Close'].shift(-1) - df['Close']) / df['Close']\n",
    "df.dropna(inplace=True)"
   ],
   "id": "7385617287da30ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Scale the data and split into train/test sets**",
   "id": "1c94ce6661a68015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=['Target'])\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ],
   "id": "93f2dce85d332ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traditional ML models (LinearRegression, DecisionTree, RandomForest, XGBoostRegressor)",
   "id": "fe2e847bcf222388"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Configure params for each traditional model to be run by GridSearchCV to pick the best one**",
   "id": "f36247989f025e82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid_lr = {\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "model_and_params = [\n",
    "    ('LinearRegression', LinearRegression(), param_grid_lr),\n",
    "    ('DecisionTreeRegressor', DecisionTreeRegressor(), param_grid_dt),\n",
    "    ('RandomForestRegressor', RandomForestRegressor(), param_grid_rf),\n",
    "    ('XGBRegressor', XGBRegressor(), param_grid_xgb),\n",
    "]"
   ],
   "id": "3a4d06e405337380",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grid_search_cv(model, param_grid, X_train, y_train, n_jobs=-1, cv=5):\n",
    "    searcher = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=n_jobs, cv=cv, scoring='neg_mean_squared_error')\n",
    "    searcher.fit(X_train, y_train)\n",
    "    return searcher\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train_and_get_best_estimator(model, param_grid):\n",
    "    grid_search = grid_search_cv(model, param_grid, X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    return best_estimator\n",
    "\n",
    "def evaluate_all_models():\n",
    "    evaluation_results = []\n",
    "    for name, model, param_grid in model_and_params:\n",
    "        estimator = train_and_get_best_estimator(model, param_grid)\n",
    "        rmse = evaluate_model(estimator, X_test, y_test)\n",
    "        evaluation_results.append((name, rmse))\n",
    "    return evaluation_results\n",
    "    "
   ],
   "id": "e0c1f586061e84c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = evaluate_all_models()",
   "id": "3aaf7a95c21997f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, rmse in results:\n",
    "    print(name, rmse)"
   ],
   "id": "bdd318cb3b282e5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NN models for stock predictions - LSTM and CNN",
   "id": "2d1dc562ff30562d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Conv1D, Flatten, MaxPooling1D\n",
    "\n",
    "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_model = build_lstm_model(input_shape)\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "# lstm_model.summary()\n",
    "# cnn_model.summary()"
   ],
   "id": "a92ac5ecc853644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "cnn_history = cnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ],
   "id": "257e5ccb88b2d54f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_nn(model, X_train, X_test, y_train, y_test, scaler):\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "\n",
    "    # Invert scaling for prediction\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    \n",
    "    # Invert scaling for actual values\n",
    "    y_train_inv = scaler.inverse_transform(y_train)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "    \n",
    "    print(f'{model.__class__} Training RMSE: {train_rmse}')\n",
    "    print(f'{model.__class__} Testing RMSE: {test_rmse}')"
   ],
   "id": "a3f05f12bc0c8078",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluate_nn(lstm_model, X_train, X_test, y_train, y_test, scaler)\n",
    "evaluate_nn(cnn_model, X_train, X_test, y_train, y_test, scaler)"
   ],
   "id": "fa5659b4d2b9db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:50:23.550138Z",
     "start_time": "2024-06-08T21:50:23.545716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_df = pd.read_csv('output/20240609031919_results.csv')\n",
    "res_df"
   ],
   "id": "ea3c0dd7ce8be75e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Symbol  LinearRegression  DecisionTreeRegressor  \\\n",
       "0         ABB.NS          0.024457               0.025257   \n",
       "1    ADANIENT.NS          0.027825               0.028469   \n",
       "2         ACC.NS          0.018020               0.018701   \n",
       "3    AARTIIND.NS          0.021668               0.021703   \n",
       "4  ABBOTINDIA.NS          0.011072               0.012505   \n",
       "\n",
       "   RandomForestRegressor  XGBRegressor  \n",
       "0               0.023689      0.024130  \n",
       "1               0.026114      0.025438  \n",
       "2               0.016998      0.016257  \n",
       "3               0.021667      0.022929  \n",
       "4               0.010711      0.010824  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABB.NS</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.024130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.028469</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>0.025438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACC.NS</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.016257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AARTIIND.NS</td>\n",
       "      <td>0.021668</td>\n",
       "      <td>0.021703</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.022929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBOTINDIA.NS</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.010824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:51:23.909442Z",
     "start_time": "2024-06-08T21:51:23.903971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summary = res_df.describe(percentiles=[0.75, 0.95])\n",
    "print(summary)"
   ],
   "id": "e2ba2ac15f1cd7c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LinearRegression  DecisionTreeRegressor  RandomForestRegressor  \\\n",
      "count          5.000000               5.000000               5.000000   \n",
      "mean           0.020608               0.021327               0.019836   \n",
      "std            0.006435               0.006151               0.006102   \n",
      "min            0.011072               0.012505               0.010711   \n",
      "50%            0.021668               0.021703               0.021667   \n",
      "75%            0.024457               0.025257               0.023689   \n",
      "95%            0.027151               0.027826               0.025629   \n",
      "max            0.027825               0.028469               0.026114   \n",
      "\n",
      "       XGBRegressor  \n",
      "count      5.000000  \n",
      "mean       0.019916  \n",
      "std        0.006192  \n",
      "min        0.010824  \n",
      "50%        0.022929  \n",
      "75%        0.024130  \n",
      "95%        0.025176  \n",
      "max        0.025438  \n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:18:43.097191Z",
     "start_time": "2024-06-08T22:18:43.095085Z"
    }
   },
   "cell_type": "code",
   "source": "summary.loc['95%'].idxmin()",
   "id": "ed2a92038a3ef475",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBRegressor'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f5589b432411ca9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
